<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Chris' Blog</title>
    <description>关于码农、搬砖工、Hacker与Runner | 这里是 @来自COOP楼长的个人博客，与你一起发现更远的世界。</description>
    <link>http://localhost:4000/</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Wed, 15 Nov 2017 23:50:55 -0800</pubDate>
    <lastBuildDate>Wed, 15 Nov 2017 23:50:55 -0800</lastBuildDate>
    <generator>Jekyll v3.4.3</generator>
    
      <item>
        <title>Tensorflow学习笔记一 —— 从源码编译到部署安装</title>
        <description>&lt;blockquote&gt;
  &lt;p&gt;Key Words: Tensorflow, Bazel, CC&amp;amp;Python, Cuda&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;主流深度学习框架对比&quot;&gt;主流深度学习框架对比&lt;/h2&gt;

&lt;p&gt;在进入一个领域之前，第一件紧要事就是寻找领域的“巨头”，也即代表性产品，以作为进入的敲门砖。深度学习领域近几年迅速发展，已经有多个成熟的开源框架可供选择，俨然成为了Big Data领域继Hadoop、Spark、图计算、流计算之后的又一战略高地。&lt;/p&gt;

&lt;p&gt;2016年发表于KDD的论文《&lt;a href=&quot;https://arxiv.org/pdf/1511.06435.pdf&quot;&gt;Comparative Study of Deep Learning Software Frameworks&lt;/a&gt;》对已有框架进行了详细论述，目前主流的开源框架包括：Caffe2，Torch，MXNet，Tensorflow等。&lt;/p&gt;

&lt;p&gt;笔者计划在后续工作中对框架源码进行修改并移植至手机端，因此在进行技术选型时从以下几个方面进行了考量：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;设计语言&lt;/li&gt;
  &lt;li&gt;目前在工业界和学术界的接受度&lt;/li&gt;
  &lt;li&gt;源码的可读性&lt;/li&gt;
  &lt;li&gt;相关技术文档的完善度&lt;/li&gt;
  &lt;li&gt;目前对于手机端的支持情况&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;通过以上五方面的对比，笔者最终选择了&lt;a href=&quot;https://arxiv.org/pdf/1603.04467.pdf&quot;&gt;Tensorflow&lt;/a&gt;框架。&lt;/p&gt;

&lt;p&gt;这一框架主体由C++语言编写，C家族是学习系统层或以下所必备的语言，底层的资源管理完全要依托于C／汇编层级，相比之下，Java实在过于上层，不利于对整个系统的深入理解。&lt;/p&gt;

&lt;p&gt;Tensorflow由Google设计并开源，G的技术水平和推广能力毋庸置疑，它在学术界和工业界的号召力保证了TF在未来一段时间的生命力，这一点从GitHub上被Star和Fork的数量可以判断。&lt;/p&gt;

&lt;p&gt;TF是谷歌集中很多领域专家搞起来的，里面优秀的设计思想和实现非常值得学习，大名鼎鼎的Jeffrey Dean正是TF的重要设计者之一，很多独当一面的大牛在这里都干起了调bug的本行…&lt;/p&gt;

&lt;p&gt;Google对TF进行了大量人力和财力的投入，这些正规军保证了TF的文档资料不会像一些开源社区那样半途而废或者杂乱无章。&lt;/p&gt;

&lt;p&gt;目前TF的某些功能已可以支持Android系统，截止撰文时笔者还没有在移动端进行尝试，但估计做的还很简陋。&lt;/p&gt;

&lt;h2 id=&quot;tensorflow安装&quot;&gt;Tensorflow安装&lt;/h2&gt;

&lt;p&gt;我们首先来看一下怎样对TF直接安装，这里笔者的操作系统是Ubuntu-14.04。&lt;/p&gt;

&lt;p&gt;对于TF的安装，以及相关编译链的构建，注意：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;版本很重要，版本很重要，版本很重要！&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;这里我们选择Tensorflow-1.3进行安装，截至撰文，r1.3是仅次于master的branch，属于次新的版本。（master版本太新，介绍文档以及与其它软件的兼容匹配度还不成熟）。&lt;/p&gt;

&lt;p&gt;确定TF版本之后开始准备搭建环境。&lt;/p&gt;

&lt;p&gt;一、Cuda安装&lt;/p&gt;

&lt;p&gt;Cuda(Compute Unified Device Architecture)，是英伟达公司推出的一种基于新的并行编程模型和指令集架构的通用计算架构，它能利用英伟达GPU的并行计算引擎，比CPU更高效的解决许多复杂计算任务。&lt;/p&gt;

&lt;p&gt;Cuda的官方下载地址为：&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://developer.nvidia.com/cuda-downloads&quot;&gt;https://developer.nvidia.com/cuda-downloads&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这里需要在NVIDA官网注册一个免费用户才能下载，注册账号：l###@163.com，密码：Us123456。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2017-09-11-tensorflow-building-from-source/Cuda.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这里安装类型选择 deb(local)。&lt;/p&gt;

&lt;p&gt;下载文件cuda-repo-ubuntu1404-8-0-local-ga2_8.0.61-1_amd64.deb（1.9GB），版本为8.0。&lt;/p&gt;

&lt;p&gt;将文件下载至“／home/chrisli/Cloud/Tensorflow/”目录：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2017-09-11-tensorflow-building-from-source/ls.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;执行命令：&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;sudo dpkg -i cuda-repo-ubuntu1404-8-0-local-ga2_8.0.61-1_amd64.deb
&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;sudo apt-get update
&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;sudo apt-get install cuda
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;默认安装在：/usr/local/cuda&lt;/p&gt;

&lt;p&gt;二、cuDNN安装&lt;/p&gt;

&lt;p&gt;NVIDIA cuDNN是用于深度神经网络的GPU加速库。它强调性能、易用性和低内存开销。&lt;/p&gt;

&lt;p&gt;cuDNN下载地址：&lt;a href=&quot;https://developer.nvidia.com/cudnn&quot;&gt;https://developer.nvidia.com/cudnn&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这里注意，选择的cuDNN版本既要和Cuda兼容，又要支持1.3版本的Tensorflow。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2017-09-11-tensorflow-building-from-source/CuDNN.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;我们选择了“cuDNN v6.0 for CUDA 8.0”，上图中需要下载的是 “cuDNN v6.0 Library for Linux”而不是deb文件，在初期笔者曾犯过这个错误。&lt;/p&gt;

&lt;p&gt;同上，输入以下命令：&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;tar xvzf cudnn-7.0-linux-x64-v4.0-prod.tgz

&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;sudo cp cuda/include/cudnn.h /usr/local/cuda/include

&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;sudo cp cuda/lib64/libcudnn&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; /usr/local/cuda/lib64

&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;sudo chmod a+r /usr/local/cuda/lib64/libcudnn&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;安装完成之后，可以通过如下命令分别查看Cuda和cuDNN的版本信息：&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;cat /usr/local/cuda/version.txt
&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;三、Python开发环境&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;sudo apt-get install python-numpy python-pip swig python-dev python-wheel
&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;sudo pip install six numpy wheel
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;根据官网描述，需要安装python3.x版本的，可以执行如下操作：&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;sudo apt-get install python3-numpy python3-dev python3-pip python3-wheel
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;这里笔者使用的2.7版本，并未对3.x版进行尝试。&lt;/p&gt;

&lt;p&gt;四、Tensorflow下载安装&lt;/p&gt;

&lt;p&gt;在终端利用pip直接安装&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;sudo pip install --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-1.3.0-cp27-none-linux_x86_64.whl
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;注意，这里的“tensorflow-1.3.0-cp27-none-linux_x86_64.whl”安装包，也就是我们后面编译源码的目标，对TF源码编译的最终结果就是生成这样一个安装包，然后本地进行安装。&lt;/p&gt;

&lt;p&gt;五、检验是否安装成功&lt;/p&gt;

&lt;p&gt;通过如下一段代码检验是否安装成功：&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;python
...
&lt;span class=&quot;gp&quot;&gt;&amp;gt;&amp;gt;&amp;gt; &lt;/span&gt;import tensorflow as tf
&lt;span class=&quot;gp&quot;&gt;&amp;gt;&amp;gt;&amp;gt; &lt;/span&gt;hello &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; tf.constant&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'Hello, TensorFlow!'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;gp&quot;&gt;&amp;gt;&amp;gt;&amp;gt; &lt;/span&gt;sess &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; tf.Session&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;gp&quot;&gt;&amp;gt;&amp;gt;&amp;gt; &lt;/span&gt;print&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;sess.run&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;hello&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
Hello, TensorFlow!
&lt;span class=&quot;gp&quot;&gt;&amp;gt;&amp;gt;&amp;gt; &lt;/span&gt;a &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; tf.constant&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;10&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;gp&quot;&gt;&amp;gt;&amp;gt;&amp;gt; &lt;/span&gt;b &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; tf.constant&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;32&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;gp&quot;&gt;&amp;gt;&amp;gt;&amp;gt; &lt;/span&gt;print&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;sess.run&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;a + b&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
42
&amp;gt;&amp;gt;&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;从安装进度来看，输入“import tensorflow as tf”语句仅仅算是完成了一半，因为各式各样的ERROR在敲下回车键后出现，详情会在［疑难问题］一章总结。&lt;/p&gt;

&lt;h2 id=&quot;编译环境搭建&quot;&gt;编译环境搭建&lt;/h2&gt;

&lt;p&gt;一、Bazel安装&lt;/p&gt;

&lt;p&gt;Bazel是Google开源构建工具，类似于Make的工具，用来编译Tensorflow。&lt;/p&gt;

&lt;p&gt;Bazel目前已被Google开源并托管在GitHub，地址：&lt;a href=&quot;https://github.com/bazelbuild/bazel/releases&quot;&gt;https://github.com/bazelbuild/bazel/releases&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这里下载的是.sh的脚本文件，我们选择版本bazel-0.5.4。&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;sudo apt-get install pkg-config zip g++zlib1g-dev unzip
&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;chmod +x bazel-0.5.4-installer-linux-x86_64.sh
&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;./bazel-0.5.4-installer-linux-x86_64.sh --user
&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;PATH&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$PATH&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$HOME&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;/bin&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;除了手动安装，bazel也支持通过apt-get直接安装，这种方式更为简便，当然对版本选择的控制力会被削弱。&lt;/p&gt;

&lt;p&gt;详细步骤可参考：&lt;a href=&quot;https://docs.bazel.build/versions/master/install-ubuntu.html&quot;&gt;https://docs.bazel.build/versions/master/install-ubuntu.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;二、TensorFlow源码下载&lt;/p&gt;

&lt;p&gt;TF源码同样托管于GitHub：&lt;a href=&quot;https://github.com/tensorflow/tensorflow&quot;&gt;https://github.com/tensorflow/tensorflow&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;注意默认Branch是master，但master在编译时仍有问题（版本兼容性问题），所以这里选择克隆r1.3版。&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;git clone -b r1.3 https://github.com/tensorflow/tensorflow.git
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;可以通过 git branch 确认分支。&lt;/p&gt;

&lt;p&gt;三、配置文件&lt;/p&gt;

&lt;p&gt;编译前通过Configure文件进行配置。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ cd tensorflow  # cd to the top-level directory created
$ ./configure
Please specify the location of python. [Default is /usr/bin/python]: /usr/bin/python2.7
Found possible Python library paths:
/usr/local/lib/python2.7/dist-packages
/usr/lib/python2.7/dist-packages
Please input the desired Python library path to use.  Default is [/usr/lib/python2.7/dist-packages]

Using python library path: /usr/local/lib/python2.7/dist-packages
Do you wish to build TensorFlow with MKL support? [y/N]
No MKL support will be enabled for TensorFlow
Please specify optimization flags to use during compilation when bazel option &quot;--config=opt&quot; is specified [Default is -march=native]:
Do you wish to use jemalloc as the malloc implementation? [Y/n]
jemalloc enabled
Do you wish to build TensorFlow with Google Cloud Platform support? [y/N]
No Google Cloud Platform support will be enabled for TensorFlow
Do you wish to build TensorFlow with Hadoop File System support? [y/N]
No Hadoop File System support will be enabled for TensorFlow
Do you wish to build TensorFlow with the XLA just-in-time compiler (experimental)? [y/N]
No XLA support will be enabled for TensorFlow
Do you wish to build TensorFlow with VERBS support? [y/N]
No VERBS support will be enabled for TensorFlow
Do you wish to build TensorFlow with OpenCL support? [y/N]
No OpenCL support will be enabled for TensorFlow
Do you wish to build TensorFlow with CUDA support? [y/N] Y
CUDA support will be enabled for TensorFlow
Do you want to use clang as CUDA compiler? [y/N]
nvcc will be used as CUDA compiler
Please specify the Cuda SDK version you want to use, e.g. 7.0. [Leave empty to default to CUDA 8.0]: 8.0
Please specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:
Please specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]:
Please specify the cuDNN version you want to use. [Leave empty to default to cuDNN 6.0]: 6
Please specify the location where cuDNN 6 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:
Please specify a list of comma-separated Cuda compute capabilities you want to build with.
You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.
Please note that each additional compute capability significantly increases your build time and binary size.
[Default is: &quot;3.5,5.2&quot;]: 3.0
Do you wish to build TensorFlow with MPI support? [y/N] 
MPI support will not be enabled for TensorFlow
Configuration finished
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;四、编译&lt;/p&gt;

&lt;p&gt;随后，执行如下命令进行编译：&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;bazel build --config&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;opt //tensorflow/tools/pip_package:build_pip_package
&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;如果支持Cuda，可以：&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;bazel build --config&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;opt --config&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;cuda //tensorflow/tools/pip_package:build_pip_package
&lt;span class=&quot;gp&quot;&gt;$ &lt;/span&gt;bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;执行成功后，会生成安装包，直接本地安装即可：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ sudo pip install /tmp/tensorflow_pkg/tensorflow-1.3.0-cp27-none-linux_x86_64.whl
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;当然，各种奇葩问题会出现在编译阶段。&lt;/p&gt;

&lt;h2 id=&quot;疑难问题&quot;&gt;疑难问题&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;以下问题均在笔者动手部署时出现过，其中部分源码引自网络。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;一、ImportError: No module named ‘_pywrap_tensorflow_internal’ 解决方法&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt;import tensorflow
Traceback (most recent call last):
File &quot;C:\Program Files\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py&quot;, line 18, in swig_import_helper
return importlib.import_module(mname)
File &quot;C:\Program Files\Anaconda3\lib\importlib\__init__.py&quot;, line 126, in import_module
return _bootstrap._gcd_import(name[level:], package, level)
File &quot;&amp;lt;frozen importlib._bootstrap&amp;gt;&quot;, line 986, in _gcd_import
File &quot;&amp;lt;frozen importlib._bootstrap&amp;gt;&quot;, line 969, in _find_and_load
File &quot;&amp;lt;frozen importlib._bootstrap&amp;gt;&quot;, line 958, in _find_and_load_unlocked
File &quot;&amp;lt;frozen importlib._bootstrap&amp;gt;&quot;, line 666, in _load_unlocked
File &quot;&amp;lt;frozen importlib._bootstrap&amp;gt;&quot;, line 577, in module_from_spec
File &quot;&amp;lt;frozen importlib._bootstrap_external&amp;gt;&quot;, line 906, in create_module
File &quot;&amp;lt;frozen importlib._bootstrap&amp;gt;&quot;, line 222, in _call_with_frames_removed
ImportError: DLL load failed: 找不到指定的模块。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
File &quot;C:\Program Files\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py&quot;, line 41, in &amp;lt;module&amp;gt;
from tensorflow.python.pywrap_tensorflow_internal import *
File &quot;C:\Program Files\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py&quot;, line 21, in &amp;lt;module&amp;gt;
_pywrap_tensorflow_internal = swig_import_helper()
File &quot;C:\Program Files\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py&quot;, line 20, in swig_import_helper
return importlib.import_module('_pywrap_tensorflow_internal')
File &quot;C:\Program Files\Anaconda3\lib\importlib\__init__.py&quot;, line 126, in import_module
return _bootstrap._gcd_import(name[level:], package, level)
ImportError: No module named '_pywrap_tensorflow_internal'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
File &quot;C:\Program Files\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py&quot;, line 41, in &amp;lt;module&amp;gt;
from tensorflow.python.pywrap_tensorflow_internal import *
File &quot;C:\Program Files\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py&quot;, line 21, in &amp;lt;module&amp;gt;
_pywrap_tensorflow_internal = swig_import_helper()
File &quot;C:\Program Files\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py&quot;, line 20, in swig_import_helper
return importlib.import_module('_pywrap_tensorflow_internal')
File &quot;C:\Program Files\Anaconda3\lib\importlib\__init__.py&quot;, line 126, in import_module
return _bootstrap._gcd_import(name[level:], package, level)
ImportError: No module named '_pywrap_tensorflow_internal'


Failed to load the native TensorFlow runtime.
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;这个是由于我之前一个没注意装了cudnn3.0，而r1.3版的tensorflow，需要cudnn6.0&lt;/p&gt;

&lt;p&gt;所以把cudnn3.0换成cudnn6.0就好了&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;二、error in Building tensor flow. [sun.security.validator.ValidatorException:] #12874&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;解决方案： &lt;br /&gt;
i solved it by changing branch r1.3 -&amp;gt;./configure -&amp;gt; build.&lt;br /&gt;
May be issue with latest master code.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;三、tensorflow build error with bazel (-c to -s)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;笔者最初编译时总是出错，直到把参数-c改为-s，第一次编译通过&lt;br /&gt;
bazel build -s //tensorflow/tools/pip_package:build_pip_package&lt;br /&gt;
奇怪的是，将参数变回来也通过了，任性。。。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;四、Cannot import tensorflow in python #1013&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; import tensorflow as tf
Traceback (most recent call last):
File &quot;&amp;lt;stdin&amp;gt;&quot;, line 1, in &amp;lt;module&amp;gt;
File &quot;C:\Users\Or\AppData\Local\Enthought\Canopy\User\lib\site-packages\tensorflow\__init__.py&quot;, line 4, in &amp;lt;module&amp;gt;
from tensorflow.python import *
File &quot;C:\Users\Or\AppData\Local\Enthought\Canopy\User\lib\site-packages\tensorflow\python\__init__.py&quot;, line 22, in &amp;lt;module&amp;gt;
from tensorflow.python.client.client_lib import *
File &quot;C:\Users\Or\AppData\Local\Enthought\Canopy\User\lib\site-packages\tensorflow\python\client\client_lib.py&quot;, line 35, in &amp;lt;module&amp;gt;
from tensorflow.python.client.session import InteractiveSession
File &quot;C:\Users\Or\AppData\Local\Enthought\Canopy\User\lib\site-packages\tensorflow\python\client\session.py&quot;, line 11, in &amp;lt;module&amp;gt;
from tensorflow.python import pywrap_tensorflow as tf_session
File &quot;C:\Users\Or\AppData\Local\Enthought\Canopy\User\lib\site-packages\tensorflow\python\pywrap_tensorflow.py&quot;, line 28, in &amp;lt;module&amp;gt;
_pywrap_tensorflow = swig_import_helper()
File &quot;C:\Users\Or\AppData\Local\Enthought\Canopy\User\lib\site-packages\tensorflow\python\pywrap_tensorflow.py&quot;, line 20, in swig_import_helper
import _pywrap_tensorflow
ImportError: No module named _pywrap_tensorflow
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;对这一问题的描述主要是版本问题，牵扯到numpy、cuda、cudnn等多个方面，具体可见&lt;a href=&quot;https://github.com/tensorflow/tensorflow/issues/1013&quot;&gt;https://github.com/tensorflow/tensorflow/issues/1013&lt;/a&gt;的讨论。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;五、AttributeError: type object ‘NewBase’ has no attribute ‘is_abstract’ #2016&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; import tensorflow as tf I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally Traceback (most recent call last): File &quot;&amp;lt;stdin&amp;gt;&quot;, line 1, in &amp;lt;module&amp;gt; File &quot;/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py&quot;, line 23, in &amp;lt;module&amp;gt; from tensorflow.python import * File &quot;/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py&quot;, line 94, in &amp;lt;module&amp;gt; from tensorflow.python.platform import test File &quot;/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/test.py&quot;, line 62, in &amp;lt;module&amp;gt; from tensorflow.python.framework import test_util File &quot;/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/test_util.py&quot;, line 41, in &amp;lt;module&amp;gt; from tensorflow.python.platform import googletest File &quot;/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/googletest.py&quot;, line 32, in &amp;lt;module&amp;gt; from tensorflow.python.platform import benchmark # pylint: disable=unused-import File &quot;/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/benchmark.py&quot;, line 112, in &amp;lt;module&amp;gt; class Benchmark(six.with_metaclass(_BenchmarkRegistrar, object)): File &quot;/usr/lib/python2.7/dist-packages/six.py&quot;, line 617, in with_metaclass return meta(&quot;NewBase&quot;, bases, {}) File &quot;/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/benchmark.py&quot;, line 107, in __new__ if not newclass.is_abstract(): AttributeError: type object 'NewBase' has no attribute 'is_abstract'
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;I solved this problem by reinstall the package six:&lt;br /&gt;
sudo pip uninstall six&lt;br /&gt;
sudo pip install six –upgrade –target=”/usr/lib/python2.7/dist-packages”\&lt;/p&gt;

&lt;p&gt;以上是查到的解决方案，但在卸载six时出现own by os的提示，无法卸载。&lt;/p&gt;

&lt;p&gt;通过&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;gp&quot;&gt;&amp;gt;&amp;gt;&amp;gt; &lt;/span&gt;import six
&lt;span class=&quot;gp&quot;&gt;&amp;gt;&amp;gt;&amp;gt; &lt;/span&gt;print&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;six.__version__&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;我们发现six的版本并未发生变化，这是因为six实际在本机共存了版本，但默认的那个版本没有改变，因此我们直接rm删除掉了/usr/lib/python2.7/dist-packages目录，奇迹出现了。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2017-09-11-tensorflow-building-from-source/q5.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;/img/2017-09-11-tensorflow-building-from-source/q6.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;/img/2017-09-11-tensorflow-building-from-source/q7.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;同样的问题出现在protobuf：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; import protobuf
&amp;gt;&amp;gt;&amp;gt; print protobuf.__version__
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Recently, I have learnt a simple method to get the version of the packages, such as numpy, six and protobuf, like this:&lt;br /&gt;
pip show numpy six protobuf&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;六、编译时用户所在路径问题&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;网上讨论中多次提到，在import tensorflow时要离开其所在目录。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2017-09-11-tensorflow-building-from-source/q8.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;七、RuntimeError: module compiled against API version a but this version of numpy is 9&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; runfile('/Users/isaiahnields/.spyder2/temp.py', wdir='/Users/isaiahnields/.spyder2')
RuntimeError: module compiled against API version a but this version of numpy is 9
Traceback (most recent call last):
File &quot;&amp;lt;stdin&amp;gt;&quot;, line 1, in &amp;lt;module&amp;gt;
File &quot;/Applications/Spyder-Py2.app/Contents/Resources/lib/python2.7/spyderlib/widgets/externalshell/sitecustomize.py&quot;, line 685, in runfile
execfile(filename, namespace)
File &quot;/Applications/Spyder-Py2.app/Contents/Resources/lib/python2.7/spyderlib/widgets/externalshell/sitecustomize.py&quot;, line 78, in execfile
builtins.execfile(filename, *where)
File &quot;/Users/isaiahnields/.spyder2/temp.py&quot;, line 9, in &amp;lt;module&amp;gt;
import cv
File &quot;/Applications/Spyder-Py2.app/Contents/Resources/lib/python2.7/cv.py&quot;, line 1, in &amp;lt;module&amp;gt;
from cv2.cv import *
ImportError: numpy.core.multiarray failed to import
&amp;gt;&amp;gt;&amp;gt; 
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;显然，这同样是一个版本不兼容的问题。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import numpy as np 
print np.__version__ 
print np.__path__
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;解决方案详见：&lt;br /&gt;
&lt;a href=&quot;https://stackoverflow.com/questions/33859531/runtimeerror-module-compiled-against-api-version-a-but-this-version-of-numpy-is&quot;&gt;https://stackoverflow.com/questions/33859531/runtimeerror-module-compiled-against-api-version-a-but-this-version-of-numpy-is&lt;/a&gt; &amp;amp; &lt;a href=&quot;https://stackoverflow.com/questions/28517937/how-can-i-upgrade-numpy&quot;&gt;https://stackoverflow.com/questions/28517937/how-can-i-upgrade-numpy&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2017-09-11-tensorflow-building-from-source/q9.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;八、Unable to Uninstall Program : Own by OS&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;这一问题的解决方案有：&lt;a href=&quot;https://askubuntu.com/questions/647919/unable-to-uninstall-program-own-by-os&quot;&gt;https://askubuntu.com/questions/647919/unable-to-uninstall-program-own-by-os&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;九、ImportError: Need nose &amp;gt;=0.10.0 for tests #4074 Closed&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;这是一个较明显的问题，也容易解决。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2017-09-11-tensorflow-building-from-source/q10.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;十、protobuf的安装&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;TF官方教程中并未要求必须安装protobuf，但视情况而定。如果编译或执行时有这一关键字的ERROR，需要对它进行安装。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2017-09-11-tensorflow-building-from-source/q11.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;参考博客&quot;&gt;参考博客&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://www.zhihu.com/question/46587833&quot;&gt;DL框架的未来发展，TensorFlow/MXNet/Torch, 选哪个？－知乎&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://www.zhihu.com/question/37243838&quot;&gt;如何评价Google发布的第二代深度学习系统TensorFlow?－知乎&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;http://blog.csdn.net/kkk584520/article/details/51476816&quot;&gt;TensorFlow 从入门到精通（一）：安装和使用&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;http://blog.csdn.net/luodongri/article/details/53870560?utm_source=itdadao&amp;amp;utm_medium=referral&quot;&gt;Tensorflow环境搭建-CSDN&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://www.zhihu.com/question/49909565&quot;&gt;TensorFlow 如何入门？-知乎&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://www.leiphone.com/news/201606/ORlQ7uK3TIW8xVGF.html&quot;&gt;真正从零开始，TensorFlow详细安装入门图文教程！&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

</description>
        <pubDate>Mon, 11 Sep 2017 05:00:00 -0700</pubDate>
        <link>http://localhost:4000/2017/09/11/tensorflow-building-from-source/</link>
        <guid isPermaLink="true">http://localhost:4000/2017/09/11/tensorflow-building-from-source/</guid>
        
        <category>源码阅读</category>
        
        <category>Tensorflow</category>
        
        <category>Deep learning</category>
        
        
      </item>
    
      <item>
        <title>绕过 Windows 7 登录密码的小技巧</title>
        <description>&lt;p&gt;一、Windows的登录界面&lt;/p&gt;

&lt;p&gt;如下图所示，利用终端可以绕过登录界面，直接进入这堵墙背后的C盘，D盘，E盘，et al.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2017-05-17-login-windowsOS-without-passwd/WechatIMG1.jpeg&quot; alt=&quot;img-w150&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Before that, 两个问题需要回答：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;怎样在登录界面上使用终端？&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;终端出现了，然后呢？&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;二、Q1: 怎样在登录界面上使用终端&lt;/p&gt;

&lt;p&gt;细心的童鞋会留意到，登录界面左下方有个“快速访问”的按钮，点开之后会出现各种小工具方便使用，比如“放大器”、“屏幕键盘”。&lt;/p&gt;

&lt;p&gt;只要能将终端程序替代掉“放大器”，就能直接在这里调出cmd。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2017-05-17-login-windowsOS-without-passwd/cmd.png&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;p&gt;放大器对应的程序位于 C:\Windows\System32\Magnify.exe，所以，只要用 cmd.exe 替换掉 Magnify.exe 即可。&lt;/p&gt;

&lt;p&gt;问题来了，桌面登不进去，怎么进行替换？&lt;/p&gt;

&lt;p&gt;可以利用 U 盘做一个启动项，利用启动盘的系统使用功能管理整个磁盘，找到文件并替换。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2017-05-17-login-windowsOS-without-passwd/boot.png&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;p&gt;过程中会遇到文件修改权限问题（sudo，你懂的）和 C 盘找不到的问题（利用 fdisk -l 查看挂载点，或直接 mount 挂载），总之最终结果就是：Magnify.exe 文件被 cmd.exe 文件成功替换。&lt;/p&gt;

&lt;p&gt;三、Q2: 终端出现了，然后呢？&lt;/p&gt;

&lt;p&gt;Windows 终端命令：&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$net&lt;/span&gt; user USERNAME NEW_PASSSWORD
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;这是一个逻辑上异常神奇的存在，因为用这一命令可以修改密码，而且而且，修改密码时不需要输入原密码。。。&lt;/p&gt;

&lt;p&gt;举个例子，这里楼长终端输入: net user USTCLI 123456&lt;/p&gt;

&lt;p&gt;随后关闭终端，在登录界面密码栏输入：123456，密码认证通过，顺利进入。&lt;/p&gt;

&lt;p&gt;以后再用电脑，直接上 123456 就可以了。&lt;/p&gt;

&lt;hr /&gt;

</description>
        <pubDate>Wed, 17 May 2017 05:00:00 -0700</pubDate>
        <link>http://localhost:4000/2017/05/17/login-windowsOS-without-passwd/</link>
        <guid isPermaLink="true">http://localhost:4000/2017/05/17/login-windowsOS-without-passwd/</guid>
        
        <category>Windows</category>
        
        <category>Security</category>
        
        
      </item>
    
      <item>
        <title>利用 Shadowsocks 观看完整版「人民的名义」</title>
        <description>&lt;blockquote&gt;
  &lt;p&gt;最近身边有朋友剧荒了，本着好剧大家看的原则写下此文，以介绍如何登陆 Youtube 继续追剧事业。闲话少说，直接上图：&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/img/2017-04-17-shadowsocks/shadowsocks-youku.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;基本原理&quot;&gt;基本原理&lt;/h2&gt;

&lt;p&gt;要访问需要的数据，其实原理很简单：“长城”使用的是黑名单制。设想数据由 A 传到 B 被阻止，那是因为 A 和 B 之间有道墙，墙上挂着告示（名单），上说 A 被通缉，不得入内。可是，如果把 A 的数据传给 C，再由 C 传给 B 不就可以了吗？&lt;/p&gt;

&lt;p&gt;这里有一点需要注意，那就是 C 和 A 之间不能再有“告示”，所以，C 的地理位置很重要，你懂的。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2017-04-17-shadowsocks/shadowsocks-earth.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;楼长的做法是，首先在洛杉矶搭建一台服务机，然后在大洋两端分别完成 Shadowsocks client 和 Shadowsocks server。数据流将通过一台服务器的中转进来。一切完成之后，就可以继续追剧了。&lt;/p&gt;

&lt;p&gt;除了《人民的名义》，我们也可以看到更多的新闻资料和技术材料，如 Google Scholar 等。&lt;/p&gt;

&lt;p&gt;网上的所有言论都是由人发布的，而每个人的深层动机和政治考量各不相同，相信广大同胞凭借自己的智慧足以分辨，当然这一点和技术无关。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2017-04-17-shadowsocks/shadowsocks-cnn.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;shadowsocks-server&quot;&gt;Shadowsocks Server&lt;/h2&gt;

&lt;p&gt;一. 获取硬件资源&lt;/p&gt;

&lt;p&gt;首选当然是 Google cloud platform，谷歌为了广大老百姓也是操碎了心。遗憾的是，要访问 Google 服务器就要先 FQ，而如果能 FQ 还要 Google 干嘛？这是个悖论。&lt;/p&gt;

&lt;p&gt;所以，这里我在其他榜上无名的服务商那里租来了一台小型服务器，用于满足个人需求（服务器的 CPU 和 Memory 均没有要求，但网络带宽要靠谱）。这里我选择使用的是 &lt;a href=&quot;https://my.rfchost.com/&quot;&gt;RFCHOST&lt;/a&gt;。本文并不是什么广告贴，大家用其他任何的服务商都是没有问题的。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2017-04-17-shadowsocks/shadowsocks-f.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;不过还是在啰嗦一句，租用服务器时建议将如下几点列入考虑范畴：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;价格，当然要便宜些，服务器一般有年租和月租之分，不知水深的最好短期租用；&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;选择口碑好的服务商&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;另外（划重点），&lt;b&gt;服务器一定要在境外、香港或天朝的台湾省&lt;/b&gt;。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;网上有很多为了新注册会员免费试用数月的优惠，所以即便是服务器也是可以淘到免费的。给大家个市场价，月租 5$ 左右，就足够拿到一台满足自己需求的服务器。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;以下开始技术部分！&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;二. 搭建服务器架构&lt;/p&gt;

&lt;p&gt;这里默认大家已经有一台服务器了，那么怎样在上面搭建 Shadowsocks 服务呢？这里楼长以 Ubuntu 16.04 为例介绍。&lt;/p&gt;

&lt;p&gt;首先当然是进入系统，更新一下 apt-get 软件包，这一步是所有系统安装成功后都要做的。&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$sudo&lt;/span&gt; apt-get update
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;随后，通过 apt-get 安装 python-pip&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$sudo&lt;/span&gt; apt-get install python-pip
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;完成之后使用 pip 安装 shadowsocks 服务&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$sudo&lt;/span&gt; pip install shadowsocks
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;成功安装后，我们需要创建一个shadowsocks server 的配置文件，可以直接建在当前用户目录下&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$sudo&lt;/span&gt; vim ss-conf.json
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;然后输入&lt;/p&gt;

&lt;div class=&quot;language-c highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;//使用当前服务器，填0.0.0.0
&lt;/span&gt;    &lt;span class=&quot;s&quot;&gt;&quot;server&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;0.0.0.0&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;//对外的服务端口,随意
&lt;/span&gt;    &lt;span class=&quot;s&quot;&gt;&quot;server_port&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8888&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;//本地IP和端口
&lt;/span&gt;    &lt;span class=&quot;s&quot;&gt;&quot;local_address&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;127.0.0.1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;local_port&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1080&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;//shadowsocks密码，自己设置
&lt;/span&gt;    &lt;span class=&quot;s&quot;&gt;&quot;password&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;youpassword&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;    
    &lt;span class=&quot;s&quot;&gt;&quot;timeout&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;600&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;//加密方式
&lt;/span&gt;    &lt;span class=&quot;s&quot;&gt;&quot;method&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;aes-256-cfb&quot;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;保存。&lt;/p&gt;

&lt;p&gt;最后，利用这个配置文件启动 shadowsocks 服务。&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$sudo&lt;/span&gt; ssserver -c ss-conf.json -d start
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;至此，服务器的配置也就完成了，简单吧！&lt;/p&gt;

&lt;p&gt;当然，我使用的是裸服务器，对于使用 google cloud 服务器的童鞋请注意，由于 google cloud 自带防火墙，所以我们需要在防火墙规则里加入端口白名单，否则外部是无法访问这个端口的服务的。&lt;/p&gt;

&lt;p&gt;修改防火墙设置的方法官方给出了详细说明，如下图，也可以请教&lt;a href=&quot;https://www.baidu.com/s?wd=google%20cloud%20platform%20%E9%98%B2%E7%81%AB%E5%A2%99%E4%BF%AE%E6%94%B9&amp;amp;rsv_spt=1&amp;amp;rsv_iqid=0xeb483baa0000adc7&amp;amp;issp=1&amp;amp;f=8&amp;amp;rsv_bp=0&amp;amp;rsv_idx=2&amp;amp;ie=utf-8&amp;amp;tn=baiduhome_pg&amp;amp;rsv_enter=1&amp;amp;rsv_sug3=46&amp;amp;rsv_sug1=3&amp;amp;rsv_sug7=100&amp;amp;rsv_t=3c7dR0oOboXLJECGPejbICEbc781wBiWLqGjKBK2v46p16cQs%2FFILl85DLcYUekuhTtj&amp;amp;rsv_sug2=0&amp;amp;inputT=9213&amp;amp;rsv_sug4=9214&quot;&gt;度娘&lt;/a&gt;，这里就不再赘述。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2017-04-17-shadowsocks/shadowsocks-google-platform.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;shadowsocks-client&quot;&gt;Shadowsocks client&lt;/h2&gt;

&lt;p&gt;如此一来，大洋另一端的服务器也就完成了（Shadowsocks server），下面来看看本地的客户端（Shadowsocks client）。&lt;/p&gt;

&lt;p&gt;由于客户端的多样性，这里分别介绍：&lt;/p&gt;

&lt;p&gt;&lt;b&gt;一. Windows&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;首先介绍 Windows，需要注意，在 Windows 除了安装客户端，还要对浏览器进行额外配置。这是 Windows 比其它操作系统要复杂的地方。&lt;/p&gt;

&lt;p&gt;通常情况，我们希望浏览器在访问的国外网站的时候使用shadowsocks，而访问国内网站的时候使用本地网络，比如你在优酷看视频，并不需要走一圈代理，这样速度反而会更慢。那么安利一个 chrome 下 shadowsocks 的黄金搭档，SwitchyOmega。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2017-04-17-shadowsocks/shadowsocks-switchyomega.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这个可以在 chrome 应用商店里下载安装。（配置的复杂程度和当初配 goagent 相当，求阴影面积）&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;深吸一口气，下面开始介绍本文最晦涩的一部分：&lt;b&gt;Chrome&lt;/b&gt; + &lt;b&gt;SwitchyOmega&lt;/b&gt; + &lt;b&gt;Shadowsocks&lt;/b&gt; 的黄金组合！&lt;/p&gt;

&lt;p&gt;1. 电脑端下载 shadowscoks(&lt;a href=&quot;https://github.com/shadowsocksr/shadowsocksr-csharp/releases&quot;&gt;最新版下载链接&lt;/a&gt;)，打开后开始配置，第一步选择 “编辑服务器”&lt;/p&gt;

&lt;p&gt;2. 在这里配置上你获得的 shadowsocks 的IP 端口 和密码，代理端口可以只有选择的，不过一般都选择 1080。&lt;/p&gt;

&lt;p&gt;具体配置的内容，和接下来介绍的 macbook 上的配置一样一样的，除了界面丑陋点。&lt;/p&gt;

&lt;p&gt;3. 点击下 “&lt;b&gt;从GFWLIST更新本地PAC&lt;/b&gt;“ 更新完PAC后选择 &lt;b&gt;使用本地PAC&lt;/b&gt;。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2017-04-17-shadowsocks/shadowsocks-1.jpeg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;4. 系统代理模式 选择 &lt;b&gt;PAC模式&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2017-04-17-shadowsocks/shadowsocks-2.jpeg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;5. 正常来说运行了ShadowsocksR后就可以直接访问Chrome应用商店安装了（&lt;a href=&quot;https://github.com/FelisCatus/SwitchyOmega/releases&quot;&gt;在 Github 上下载最新版安装包&lt;/a&gt;）。&lt;/p&gt;

&lt;p&gt;chrome 安装好 &lt;a href=&quot;https://chrome.google.com/webstore/detail/proxy-switchyomega/padekgcemlokbadohgkifijomclgjgif?utm_source=chrome-app-launcher-info-dialog&quot;&gt;switchyomega&lt;/a&gt; 后选择 &lt;b&gt;新建情景模式&lt;/b&gt;，&lt;b&gt;情景模式名称&lt;/b&gt; 可以随便选择 模式类型选择第一个 &lt;b&gt;代理服务器&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2017-04-17-shadowsocks/shadowsocks-new.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;6. 代理服务器按下表配置就okay了，到此也就可以正常使用了PAC模式了。但是为了更进一步更方便的使用我们还可以增加一步自动切换。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2017-04-17-shadowsocks/shadowsocks-3.jpeg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;7. 选择右边的 &lt;b&gt;自动切换/auto switch&lt;/b&gt; 最下面的 &lt;b&gt;规则列表设置&lt;/b&gt; 按下表设置就好了 规则网址也是我图上给出的这个。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2017-04-17-shadowsocks/shadowsocks-4.jpeg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这里，AutoProxy 规则列表地址有所变动，新的地址是: &lt;a href=&quot;https://raw.githubusercontent.com/gfwlist/gfwlist/master/gfwlist.txt&quot;&gt;download&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;8. 然后最关键的一步，在浏览器右上角点击插件按钮，然后选择自动切换规则模式，这样只要在规则列表里面的网站都会翻墻访问。&lt;/p&gt;

&lt;p&gt;&lt;em&gt;本部分参考：&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;&lt;a href=&quot;http://blog.sina.com.cn/s/blog_76ed34130102vl8r.html&quot;&gt;Chrome+SwitchyOmega+Shadowsocks 完整篇&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;&lt;a href=&quot;https://github.com/FelisCatus/SwitchyOmega/wiki/GFWList&quot;&gt;GFWList · FelisCatus/SwitchyOmega Wiki · GitHub&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;b&gt;二. Macbook&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;Mac 和 Windows 一样，都有 Shadowsocks 客户端，可以在这里&lt;a href=&quot;https://pan.baidu.com/s/1jIkeUPo&quot;&gt;下载&lt;/a&gt;。配置的话就像这样输入，然后启动&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2017-04-17-shadowsocks/shadowsocks-mac.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;虽然很多教程声明，安装完成后不需要重启计算机即可使用服务，但从楼长的实际操作来看，还是要重启电脑的。&lt;/p&gt;

&lt;p&gt;&lt;b&gt;三. Android&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;Android 的安装是最简单的，IP 等配置和前面介绍的完全相同。&lt;/p&gt;

&lt;p&gt;这里只给出下载地址：&lt;a href=&quot;https://github.com/shadowsocks/shadowsocks-android/releases&quot;&gt;［Download］&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;对了，Shadowsocks 还有个中文名字，叫“影梭”，换了马甲还是要认识的。&lt;/p&gt;

&lt;p&gt;&lt;b&gt;四. Linux&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;由于撰写本文时楼长的 linux 电脑没开，也懒得开了，这里就不截图了。&lt;/p&gt;

&lt;p&gt;安装命令如下：&lt;/p&gt;

&lt;div class=&quot;language-sh highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$sudo&lt;/span&gt; add-apt-repository ppa:hzwhuang/ss-qt5
&lt;span class=&quot;nv&quot;&gt;$sudo&lt;/span&gt; apt-get update
&lt;span class=&quot;nv&quot;&gt;$sudo&lt;/span&gt; apt-get install shadowsocks-qt5
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;安装之后对于浏览器的配置与 Windows 类似。&lt;/p&gt;

&lt;h2 id=&quot;关于本网站的评论&quot;&gt;关于本网站的评论&lt;/h2&gt;

&lt;p&gt;在楼长的第一篇博客中介绍过本博客是如何搭建起来的，但当时对于博客重要的一环：&lt;b&gt;评论系统&lt;/b&gt; 按下不表。&lt;/p&gt;

&lt;p&gt;这其实也是 FQ 的问题，其实楼长在搭建本系统时是嵌入了评论系统的，由于国内最大的评论系统 &lt;b&gt;多说&lt;/b&gt; 在即将到来的六月一号就要关闭，我选择使用了美帝的 DISQUS，有图有真相：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2017-04-17-shadowsocks/shadowsocks-disqus.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;所以，如果作为吃瓜群众没能看到评论，说明还没 FQ 成功，后续楼长会把评论系统部分重新设计…&lt;/p&gt;

&lt;h2 id=&quot;背景&quot;&gt;背景&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://www.evernote.com/shard/s9/sh/4b3fda4c-866b-4025-987f-8328f28d6d1b/ad5beb3531adb7b7f33b30903fd6b0ff&quot;&gt;如何看待2015年8月20日 shadowsocks 作者停止维护的事件? - Shadowsocks - 知乎&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;以上。&lt;/p&gt;

&lt;hr /&gt;

</description>
        <pubDate>Mon, 17 Apr 2017 05:00:00 -0700</pubDate>
        <link>http://localhost:4000/2017/04/17/shadowsocks/</link>
        <guid isPermaLink="true">http://localhost:4000/2017/04/17/shadowsocks/</guid>
        
        <category>Google</category>
        
        <category>Shadowsocks</category>
        
        
      </item>
    
      <item>
        <title>查看HDFS文件物理存储路径的一两点思路</title>
        <description>&lt;blockquote&gt;
  &lt;p&gt;Key Words: Hadoop, NFS, Distributed File System&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;过程总览&quot;&gt;过程总览&lt;/h2&gt;

&lt;p&gt;hdfs文件均存放在datanode上，namenode上不会存放文件。当客户上传一个文件后，namenode会先对文件作相应的处理（比如按照block大小进行分割）。这里主要讲述存放的一个整体过程以及如何快速的找到存放的节点位置信息。&lt;/p&gt;

&lt;p&gt;实现namenode的源码中有一个与文件系统存储和管理有关的关键类FSNameSystem，里面有以下的一些概念：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;INode: 用来存放文件及目录的基本信息：名称，父节点、修改时间，访问时间以及UGI信息。 &lt;/li&gt;
  &lt;li&gt;INodeFile: 继承自INode，除INode信息外，还有组成这个文件的Blocks列表，重复因子，Block大小 &lt;/li&gt;
  &lt;li&gt;INodeDirectory：继承自INode，此外还有一个INode列表来组成文件或目录树结构 &lt;/li&gt;
  &lt;li&gt;Block(BlockInfo)：组成文件的物理存储，有BlockId，size ，以及时间戳 &lt;/li&gt;
  &lt;li&gt;BlocksMap: 保存数据块到INode和DataNode的映射关系 &lt;/li&gt;
  &lt;li&gt;FSDirectory：保存文件树结构，HDFS整个文件系统是通过FSDirectory来管理 &lt;/li&gt;
  &lt;li&gt;FSImage：保存的是文件系统的目录树 &lt;/li&gt;
  &lt;li&gt;FSEditlog:  文件树上的操作日志 &lt;/li&gt;
  &lt;li&gt;FSNamesystem: HDFS文件系统管理 &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;思路一&quot;&gt;思路一&lt;/h3&gt;

&lt;p&gt;Namenode内有两张重要的映射关系表：文件系统的命名空间，文件-block映射表。这对应了两个步骤：1. 文件按照blocksize分割成文件块 2. 文件块和block块的映射。&lt;/p&gt;

&lt;p&gt;至此，我们给出一个查找文件存放位置的思路，即首先找到每个文件对应的文件块。具体来说，可以通过 workspce/hdfs/name/current 目录下的edits和fsimage文件查看。&lt;/p&gt;

&lt;p&gt;注意，这里的workspace目录即为hdfs-site.xml等配置文件中所指路径。&lt;/p&gt;

&lt;p&gt;通过文件块给出的block的id号找到block信息，即可找到对应位置。这中间会找到一个BlockMap，详见参考[&lt;a href=&quot;HDFS文件系统如何查看文件对应的block. http://blog.csdn.net/xuefengmiao/article/details/25025455&quot;&gt;1&lt;/a&gt;]。&lt;/p&gt;

&lt;p&gt;current下主要有两大类文件 Edits 和 Fsimage([&lt;a href=&quot;Hadoop文件系统元数据fsimage和编辑日志edits：https://www.iteblog.com/archives/968.html&quot;&gt;2&lt;/a&gt;][&lt;a href=&quot;NameNode中的FSImage文件：https://www.cnblogs.com/miner007/p/3745332.html&quot;&gt;3&lt;/a&gt;]):&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Fsimage(文件系统元数据)：是 Hadoop 文件系统元数据的一个永久性的检查点，其中包含Hadoop文件系统中的所有目录和文件 idnode 的序列化信息&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Edits(编辑日志)：存放的是 Hadoop 文件系统的所有更新操作的路径，文件系统客户端执行的所有写操作首先会被记录到 edits 文件中&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;直接vim上面两种文件得到的是相关的序列化信息（总之类似乱码，看不懂）；需要运用 hadoop 提供的相关机制进行查看（参考[&lt;a href=&quot;Hadoop-2.4.1学习之edits和fsimage查看器：http://blog.csdn.net/skywalker_only/article/details/40650427&quot;&gt;4&lt;/a&gt;][&lt;a href=&quot;查看fsimage和edits：http://blog.csdn.net/baolibin528/article/details/44995541&quot;&gt;5&lt;/a&gt;]）。&lt;/p&gt;

&lt;p&gt;– Fsimage&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$cd ~/workspace/.../current
$hdfs oiv -p XML -i /home/hadoop/cloud/workspace/hdfs/name/current/fsimage_xxx -o fsimage1.xml
$vim fsimage1.xml
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;– Edits&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$cd ~/workspace/.../current
$hdfs oev -i /home/hadoop/cloud/workspace/hdfs/name/current/edits_xxx -o edits1.xml
$vim edits.xml
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;相关的fsimage和edits的资料可参见[&lt;a href=&quot;hadoop知识之fsimage和editlog：http://blog.csdn.net/maixia24/article/details/38396281&quot;&gt;6&lt;/a&gt;][&lt;a href=&quot;hdfs里的文件下载HDFS之fsimage、metadata、edits、fstime：https://www.cnblogs.com/zlslch/p/5836961.html&quot;&gt;7&lt;/a&gt;]。&lt;/p&gt;

&lt;p&gt;在上面提到的datanode下的current下面会有一个BP开头的目录，里面有个current/finalized，这就是存储的各个文件块block。&lt;/p&gt;

&lt;h3 id=&quot;思路二&quot;&gt;思路二&lt;/h3&gt;

&lt;p&gt;Hadoop直接提供了查找datanode信息的指令fsck [&lt;a href=&quot;hdfs fsck命令查看HDFS文件对应的文件块信息(Block)和位置信息：http://lxw1234.com/archives/2015/08/452.htm&quot;&gt;8&lt;/a&gt;]&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$hdfs fsck /input -files -blocks -locations -racks
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;files 代表检出所有文件状态&lt;/li&gt;
  &lt;li&gt;blocks 代表打印文件的block报告&lt;/li&gt;
  &lt;li&gt;locations代表打印出文件存放的datanode（分成多少文件块就打印出多少条信息）&lt;/li&gt;
  &lt;li&gt;racks代表打印出存放的机架位置&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

</description>
        <pubDate>Fri, 24 Mar 2017 05:00:00 -0700</pubDate>
        <link>http://localhost:4000/2017/03/24/hadoop-fsimage/</link>
        <guid isPermaLink="true">http://localhost:4000/2017/03/24/hadoop-fsimage/</guid>
        
        <category>Big Data</category>
        
        <category>Hadoop</category>
        
        
      </item>
    
      <item>
        <title>如何实现分布式文件系统HDFS到本地Linux文件系统的映射</title>
        <description>&lt;blockquote&gt;
  &lt;p&gt;Key Words: Hadoop, NFS, Distributed File System&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;为什么需要文件系统间的映射&quot;&gt;为什么需要文件系统间的映射&lt;/h2&gt;

&lt;p&gt;hdfs是分布式系统，要想访问hdfs上的文件，可以用java api或者hadoop shell等工具。遗憾的是，很多应用包无法直接调用这些api，因此，如果想操作hdfs文件系统就像操作本地文件系统一样的便捷，实现两者之间的映射是我们想到的最好的解决方案。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2017-03-20-hadoop-dfs-nfs-lfs/architecture.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;已有解决方案介绍&quot;&gt;已有解决方案介绍&lt;/h2&gt;

&lt;p&gt;目前已有解决方案有三种。其中，《Hadoop权威指南》一书中提到，可以通过Fuse－DFS和WebDEV两种途径实现，如下所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2017-03-20-hadoop-dfs-nfs-lfs/fuse2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;遗憾的是，楼长在部署时发现上述方式过于繁琐。相较之下，第三种解决方案：NFS挂载，则更为实用。&lt;/p&gt;

&lt;h2 id=&quot;基于nfs的解决方案实践&quot;&gt;基于NFS的解决方案实践&lt;/h2&gt;

&lt;p&gt;为通过NFS技术实现HDFS到本地的挂载，进而完成映射，我们分两步走。&lt;/p&gt;

&lt;p&gt;一. 本地目录到本地目录的挂载&lt;/p&gt;

&lt;p&gt;首先需要安装nfs服务&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$sudo apt-get install nfs-kernel-server
$sudo apt-get install nfs-client
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;安装完成后，更新/etc/exports文件，并在最后添加如下一行：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/ *(insecure, rw, async, no_root_squash)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;其中，“／”表示准备被挂载的目录， “＊”对应允许挂载的IP地址，这里表示所有。&lt;/p&gt;

&lt;p&gt;安装完成后，启动nfs服务：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$sudo /etc/init.d/rpcbind start
$sudo /etc/init.d/nfs-kernel-server start
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;最后，实现挂载。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$sudo mount 192.168.0.123:/input /mnt
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;二. HDFS到本地目录的挂载&lt;/p&gt;

&lt;p&gt;这一部分是实际操作中bug频出的地方，归根结底是配置文件的错误。对core-site.xml和hdfs-site.xml两大文件，分别添加如下内容：&lt;/p&gt;

&lt;p&gt;– core-site.xml&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;property&amp;gt;
&amp;lt;name&amp;gt;hadoop.proxyuser.root.groups&amp;lt;/name&amp;gt;
&amp;lt;value&amp;gt;*&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;

&amp;lt;property&amp;gt;
&amp;lt;name&amp;gt;hadoop.proxyuser.root.hosts&amp;lt;/name&amp;gt;
&amp;lt;value&amp;gt;192.168.0.123&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;注意，这里&lt;name&gt;标签里的“root”，在很多教程里写成“nfsserver”或&quot;hadoop&quot;，在楼长的实际操作中，只有“root”不报错。&lt;/name&gt;&lt;/p&gt;

&lt;p&gt;– hdfs-site.xml&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;property&amp;gt;
&amp;lt;name&amp;gt;dfs.namenode.accesstime.precision&amp;lt;/name&amp;gt;
&amp;lt;value&amp;gt;3600000&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;

&amp;lt;property&amp;gt;
&amp;lt;name&amp;gt;nfs.dump.dir&amp;lt;/name&amp;gt;
&amp;lt;value&amp;gt;/tmp/.hdfs-nfs&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;

&amp;lt;property&amp;gt;
&amp;lt;name&amp;gt;nfs.exports.allowed.hosts&amp;lt;/name&amp;gt;
&amp;lt;value&amp;gt;* rw&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;配置文件更新后，同步到各节点，并启动集群。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$sbin/start-all.sh
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;使用以下命令启动hadoop中的nfs服务：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$sudo /etc/init.d/nfs-kernel-server stop
$sudo /etc/init.d/rpcbind stop
$sudo ./hadoop-daemon.sh start portmap
$sudo ./hadoop-daemon.sh start nfs3
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;查看是否成功：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$sudo rpcinfo -p 192.168.0.123
$sudo showmount -e 192.168.0.123
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;服务启起来之后，实现挂载：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$sudo mount -t nfs -o vers=3,proto=tcp,nolock,noacl 192.168.0.123:/ /mnt
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;hr /&gt;

</description>
        <pubDate>Mon, 20 Mar 2017 05:00:00 -0700</pubDate>
        <link>http://localhost:4000/2017/03/20/hadoop-dfs-nfs-lfs/</link>
        <guid isPermaLink="true">http://localhost:4000/2017/03/20/hadoop-dfs-nfs-lfs/</guid>
        
        <category>Big Data</category>
        
        <category>Hadoop</category>
        
        
      </item>
    
      <item>
        <title>「51CTO」Hadoop平台与开发环境搭建</title>
        <description>&lt;blockquote&gt;
  &lt;p&gt;文章转自我在 51CTO 的一篇网络课程，如下是楼长 2014 年录的一段操作视频，供大家参考。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&quot;https://pan.baidu.com/s/1jI9htgq&quot;&gt;&lt;img src=&quot;/img/2017-03-16-hadoop-implementation/hadoop-video.png&quot; alt=&quot;&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;准备工作&quot;&gt;准备工作&lt;/h2&gt;

&lt;p&gt;1. 集群安装 ubuntu 系统，用户名：hadoop，密码自设。&lt;/p&gt;

&lt;p&gt;2. 使用 &lt;b&gt;$ifconfig&lt;/b&gt; 命令查看网络信息，并据此将 IP 等设置为静态。集群相应网络参数如下表，这里我们使用了三台 Linux 来部署Hadoop。&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Host Name&lt;/th&gt;
      &lt;th&gt;User Name&lt;/th&gt;
      &lt;th&gt;IP Address&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Master&lt;/td&gt;
      &lt;td&gt;hadoop&lt;/td&gt;
      &lt;td&gt;10.0.1.27&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Slave_one&lt;/td&gt;
      &lt;td&gt;hadoop&lt;/td&gt;
      &lt;td&gt;10.0.1.39&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Slave_two&lt;/td&gt;
      &lt;td&gt;hadoop&lt;/td&gt;
      &lt;td&gt;10.0.1.40&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;3. 实现 ssh 服务，命令：&lt;b&gt;$sudo apt-get install openssh-server&lt;/b&gt;（不需要重启）。&lt;/p&gt;

&lt;p&gt;4. 使用命令：&lt;b&gt;$ssh hadoop@10.0.1.27&lt;/b&gt; 测试服务连接是否正常。&lt;/p&gt;

&lt;p&gt;5. 设置无密钥登录&lt;/p&gt;

&lt;p&gt;各节点生成密钥：&lt;b&gt;$ssh-keygen&lt;/b&gt;，之后会在 /home/hadoop/ 路径下生成 .ssh 文件夹；&lt;/p&gt;

&lt;p&gt;将各节点的 id_rsa.pub 文件集中到 Master：&lt;/p&gt;

&lt;p&gt;&lt;b&gt;$scp ~/.ssh/id_rsa.pub hadoop@10.0.1.27:/home/hadoop/keygen/&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;将各节点 id_rsa.pub 中的内容追加到authorized_keys文件：&lt;/p&gt;

&lt;p&gt;&lt;b&gt;$cat id_rsa.pub » ../.ssh/authorized_keys&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;随后，将 authorized_keys 文件分发到各个节点：&lt;/p&gt;

&lt;p&gt;&lt;b&gt;$scp ~/.ssh/authorized_keys hadoop@10.0.1.27:/home/hadoop/.ssh/
&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;如此,就实现了各节点间的无密钥登录。注意:无密钥登录是集群正常运行的必要条件&lt;/p&gt;

&lt;p&gt;6. 设置 hostname (Master, Slave_one, Slave_two),执行命令：&lt;b&gt;$sudo vim /etc/hosts&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;7. 手动配置 JDK&lt;/p&gt;

&lt;p&gt;为了进行版本控制，这里我们手动安装 JDK。将文件夹 jdk1.7.0-40 上传到服务器各节点：&lt;/p&gt;

&lt;p&gt;&lt;b&gt;$./auto_sync_simple.sh jdk1.7.0_40 /home/hadoop/Cloud/&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;这里，auto_sync_simple.sh 是自己写的分发脚本，大家也可以命令行直接分发。&lt;/p&gt;

&lt;p&gt;接着，打开 /etc/profile 文件，追加如下信息：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-jason&quot;&gt;export JAVA_HOME=/home/hadoop/Cloud/jdk1.7.0_40
export CLASSPATH=$CLASSPATH:$JAVA_HOME/lib:$JAVA_HOME/jre/lib 
export PATH=$JAVA_HOME/bin:$JAVA_HOME/jre/bin:$PATH:$HOME/bin
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;执行命令&lt;b&gt;$. /etc/profile&lt;/b&gt; 使环境变量即时生效&lt;/p&gt;

&lt;p&gt;每个节点均如此设置,可使用 &lt;b&gt;$java -version&lt;/b&gt; 命令进行验证&lt;/p&gt;

&lt;p&gt;8. 关闭防火墙&lt;/p&gt;

&lt;p&gt;ubuntu 系统默认 iptables 是关闭的，通过命令 &lt;b&gt;$sudo ufw status&lt;/b&gt; 可查看状态&lt;/p&gt;

&lt;p&gt;关闭 SELinux: &lt;b&gt;$setenforce 0&lt;/b&gt;&lt;/p&gt;

&lt;h2 id=&quot;部署-hadoop&quot;&gt;部署 Hadoop&lt;/h2&gt;

&lt;p&gt;1. Hadoop目录结构&lt;/p&gt;

&lt;p&gt;Hadoop-2.0 以后版本较之前有较大改动&lt;/p&gt;

&lt;p&gt;由于使用 hadoop 的用户被分成了不同的用户组,就像 Linux 一样。因此执行文件和脚本被分成了
两部分,分别存放在 bin 和 sbin 目录下。&lt;/p&gt;

&lt;p&gt;存放在 sbin 目录下的是只有超级用户才有权限执行的脚本, 如 start-dfs.sh, start-yarn.sh, stop-dfs.sh, stop-yarn.sh 等,这些是对整个集群的操作,只有 superuser 才有权限。&lt;/p&gt;

&lt;p&gt;存放在 bin 目录下的脚本所有的用户都有执行的权限,这里的脚本一般都是 对集群中具体的文件或者 block pool 操作的命令,如上传文件,查看集群的使用情况等&lt;/p&gt;

&lt;p&gt;etc 目录下存放的就是在 0.23.0 版本以前 conf 目录下存放的东西,就是对 common, hdfs, mapreduce(yarn)的配置信息&lt;/p&gt;

&lt;p&gt;include 和 lib 目录下存放的是使用 Hadoop 的 C 语言接口开发用到的头文件和链接的库&lt;/p&gt;

&lt;p&gt;libexec 目录下存放的是 hadoop 的配置脚本,具体怎么用到的这些脚本,我也还没跟踪到。目前 我就是在其中 hadoop-config.sh 文件中增加了 JAVA_HOME 环境变量&lt;/p&gt;

&lt;p&gt;logs 目录在 download 到的安装包里是没有的,如果你安装并运行了 hadoop,就会生成 logs 这 个目录和里面的日志&lt;/p&gt;

&lt;p&gt;share 这个文件夹存放的是 doc 文档和最重要的 Hadoop 源代码编译生成的 jar 包文件,就是运行 hadoop 所用到的所有的 jar 包&lt;/p&gt;

&lt;p&gt;2. 从 Apache 官网可以下载最新版，本文采用的是 2.2.0，&lt;a href=&quot;http://hadoop.apache.org/ &quot;&gt;http://hadoop.apache.org/ &lt;/a&gt;&lt;/p&gt;

&lt;p&gt;3. 在服务器各节点新建 Cloud 目录，注意，各节点 Hadoop 保存的路径需要一致。&lt;/p&gt;

&lt;p&gt;4. 将从官网下载的 hadoop-2.2.0.tar.gz 上传到服务器&lt;/p&gt;

&lt;p&gt;&lt;b&gt;$scp Downloads/hadoop-2.2.0.tar.gz hadoop@10.0.1.27:/home/hadoop/Cloud/&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;解压文件：&lt;b&gt;$tar -zxvf hadoop-2.2.0.tar.gz hadoop-2.2.0&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;5. 如下文件需要配置&lt;/p&gt;

&lt;p&gt;*core-site.xml, *mapred-site.xml, *hdfs-site.xml, *yarn-site.xml, *masters, *slaves&lt;/p&gt;

&lt;p&gt;6. 编辑~/.bashrc 文件，加入如下内容&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-jason&quot;&gt;export HADOOP_PREFIX=&quot;/home/hadoop/Cloud/hadoop-2.2.0&quot; 
export PATH=$PATH:$HADOOP_PREFIX/bin
export PATH=$PATH:$HADOOP_PREFIX/sbin
export HADOOP_MAPRED_HOME=${HADOOP_PREFIX} 
export HADOOP_COMMON_HOME=${HADOOP_PREFIX} 
export HADOOP_HDFS_HOME=${HADOOP_PREFIX}
export YARN_HOME=${HADOOP_PREFIX}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;保存退出，然后执行&lt;b&gt;$source ~/.bashrc&lt;/b&gt; 使之即时生效&lt;/p&gt;

&lt;p&gt;7. 在 etc/hadoop 目录中依次编辑如上所述配置文件，若未找到 mapred-site.xml 文件可自行创建，其中 core-site.xml、mapred-site.xml、hdfs-site.xml、yarn-site.xml 为配置文件，需要着重配置，各文件配置内容如下所示:&lt;/p&gt;

&lt;p&gt;&lt;b&gt;(1) core-site.xml&lt;/b&gt;&lt;/p&gt;

&lt;div class=&quot;language-html highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt; 
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;io.native.lib.avaliable&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt; 
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;true&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;

&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt; 
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;fs.default.name&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt; 
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;hdfs://mcmaster:9000&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt; 
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;final&amp;gt;&lt;/span&gt;true&lt;span class=&quot;nt&quot;&gt;&amp;lt;/final&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;

&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;hadoop.tmp.dir&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt; 
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;/home/hadoop/Cloud/workspace/tmp&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;b&gt;(2) hdfs-site.xml&lt;/b&gt;&lt;/p&gt;

&lt;div class=&quot;language-html highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt; 
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.replication&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt; 
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;3&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;

&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt; 
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.permissions&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt; 
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;false&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;

&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.namenode.name.dir&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt; 
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;/home/hadoop/Cloud/workspace/hdfs/data&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt; 
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;final&amp;gt;&lt;/span&gt;true&lt;span class=&quot;nt&quot;&gt;&amp;lt;/final&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;

&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.namenode.dir&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt; 
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;/home/hadoop/Cloud/workspace/hdfs/name&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;

&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.datanode.dir&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt; 
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;/home/hadoop/Cloud/workspace/hdfs/data&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;

&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt; 
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;dfs.webhdfs.enabled&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt; 
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;true&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;b&gt;(3) mapred-site.xml&lt;/b&gt;&lt;/p&gt;

&lt;div class=&quot;language-html highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt; 
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;mapreduce.framework.name&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt; 
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;yarn&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt; 

&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;mapreduce.job.tracker&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt; 
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;hdfs://mcmaster:9001&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt; 
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;final&amp;gt;&lt;/span&gt;true&lt;span class=&quot;nt&quot;&gt;&amp;lt;/final&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt; 

&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;mapreduce.map.memory.mb&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;1536&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt; 
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;

&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt; 
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;mapreduce.map.java.opts&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt; 
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;-Xmx1024M&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt; 

&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;mapreduce.reduce.memory.mb&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;3072&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt; 
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;

&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt; 
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;mapreduce.reduce.java.opts&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt; 
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;-Xmx2560M&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;

&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt; 
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;mapreduce.task.io.sort.mb&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt; 
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;512&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt; 

&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;mapreduce.task.io.sort.factor&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;100&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt; 
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;

&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt; 
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;mapreduce.reduce.shuffle.parallelcopies&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt; 
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;50&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt; 

&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;mapred.system.dir&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;/home/hadoop/Cloud/workspace/mapred/system&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt; 
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;final&amp;gt;&lt;/span&gt;true&lt;span class=&quot;nt&quot;&gt;&amp;lt;/final&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt; 

&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;mapred.local.dir&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;/home/hadoop/Cloud/workspace/mapred/local&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt; 
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;final&amp;gt;&lt;/span&gt;true&lt;span class=&quot;nt&quot;&gt;&amp;lt;/final&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;b&gt;(4) yarn-site.xml&lt;/b&gt;&lt;/p&gt;

&lt;div class=&quot;language-html highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt; 
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.resourcemanager.address&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt; 
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;mcmaster:8080&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;

&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt; 
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.resourcemanager.scheduler.address&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt; 
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;mcmaster:8081&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;

&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt; 
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.resourcemanager.resource-tracker.address&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt; 
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;mcmaster:8082&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;

&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt; 
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.nodemanager.aux-services&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt; 
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;mapreduce_shuffle&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;

&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt; 
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;8. 在 etc/hadoop 目录下的 hadoop-env.sh 中添加如下内容，另需 yarn-env.sh 中填充相同的内容。&lt;/p&gt;
&lt;div class=&quot;language-html highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;export HADOOP_FREFIX=/home/hadoop/Cloud/hadoop-2.2.0 
export HADOOP_COMMON_HOME=${HADOOP_FREFIX} 
export HADOOP_HDFS_HOME=${HADOOP_FREFIX}
export PATH=$PATH:$HADOOP_FREFIX/bin
export PATH=$PATH:$HADOOP_FREFIX/sbin
export HADOOP_MAPRED_HOME=${HADOOP_FREFIX}
export YARN_HOME=${HADOOP_FREFIX}
export HADOOP_CONF_HOME=${HADOOP_FREFIX}/etc/hadoop 
export YARN_CONF_DIR=${HADOOP_FREFIX}/etc/hadoop 
export JAVA_HOME=/usr/lib/jvm/java-7-sun
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;9. 编写分发脚本，将配置完成的 hadoop 分发的所有节点&lt;/p&gt;

&lt;p&gt;&lt;b&gt;$./auto_sync_simple.sh /home/hadoop/Cloud/hadoop-2.2.0 /home/hadoop/Cloud/&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;10. 跳转到 hadoop 根目录下，格式化 namenode，随后启动集群&lt;/p&gt;

&lt;p&gt;&lt;b&gt;$bin/hdfs namenode -format sbin/start-all.sh&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;11. 登录 10.0.1.27:8080 可查看资源管理页面&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2017-03-16-hadoop-implementation/hadoop-login.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;运行示例程序&quot;&gt;运行示例程序&lt;/h2&gt;

&lt;p&gt;WordCount 是最简单也是最能体现 MapReduce 思想的程序之一，可以称为 MapReduce 版 “Hello World”，该程序的完整代码可以在 Hadoop 安装包的 “src/examples” 目录下找到。&lt;/p&gt;

&lt;p&gt;WordCount主要功能是：统计一系列文本文件中每个单词出现的次数。&lt;/p&gt;

&lt;p&gt;1. 创建本地示例文件&lt;/p&gt;

&lt;p&gt;在/home/hadoop/Cloud/hadoop-2.2.0 目录下创建示例文件 test1.txt 和 test2.txt&lt;/p&gt;

&lt;p&gt;2. 在 HDFS 上创建输入文件 &lt;b&gt;$bin/hadoop fs -mkdir /input&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;3. 上传本地文件到 HDFS 的 input 目录&lt;/p&gt;

&lt;p&gt;&lt;b&gt;$bin/hadoop fs -put test1.txt /input&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;$bin/hadoop fs -put test2.txt /input&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;4. 运行 WordCount&lt;/p&gt;

&lt;p&gt;&lt;b&gt;$bin/hadoop jar /share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar wordcount
/input /output&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;若正常执行则说明集群搭建成功!&lt;/p&gt;

&lt;h2 id=&quot;常见问题及解决方案&quot;&gt;常见问题及解决方案&lt;/h2&gt;

&lt;p&gt;1. 日志报错：&lt;/p&gt;

&lt;p&gt;&lt;em&gt;java.lang.IllegalArgumentException: The ServiceName: mapreduce.shuffle set in
yarn.nodemanager.aux-services is invalid.The valid service name should only contain a-zA-Z0-9&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;解决方法：新版本 Hadoop 的配置名有所修改，将如下配置&lt;/p&gt;

&lt;div class=&quot;language-html highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt; yarn.nodemanager.aux-services &lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt; mapreduce.shuffle &lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;改为&lt;/p&gt;

&lt;div class=&quot;language-html highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nt&quot;&gt;&amp;lt;property&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;name&amp;gt;&lt;/span&gt; yarn.nodemanager.aux-services &lt;span class=&quot;nt&quot;&gt;&amp;lt;/name&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;value&amp;gt;&lt;/span&gt; mapreduce_shuffle &lt;span class=&quot;nt&quot;&gt;&amp;lt;/value&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/property&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;2. 日志报错：&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Hadoop 2.2.0 - warning: You have loaded library /home/hadoop/2.2.0/lib/native/libhadoop.so.1.0.0
which might have disabled stack guard&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;解决方法: 由于 Hadoop 2.2.0 默认配置的 libhadoop 是32位的，在64位的操作系统环境运行过程中，会提示如上错误
需要重新编译 Hadoop 源码,得到适合的库文件,请按以下步骤执行。&lt;/p&gt;

&lt;p&gt;(1) 配置编译环境&lt;/p&gt;

&lt;p&gt;本文采用 Ubuntu 14.04 系统，首先安装编译环境&lt;/p&gt;

&lt;p&gt;&lt;b&gt;$ sudo apt-get install build-essential&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;$ sudo apt-get install g++ autoconf automake libtool cmake zlib1g-dev pkg- config libssl-dev&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;$ sudo apt-get install maven&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;(2) 配置 protobuf&lt;/p&gt;

&lt;p&gt;编译过程需要使用 protobuf，建议先行安装。截至撰文，Ubuntu 仓库默认的 protobuf 是 2.4.1 版,需要更新的
2.5 版。可从 &lt;a href=&quot;https://github.com/google/protobuf&quot;&gt;https://github.com/google/protobuf&lt;/a&gt; 下载。&lt;/p&gt;

&lt;p&gt;&lt;b&gt;$ ./configure –prefix=/usr&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;$make&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;$sudo make install&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;可通过 &lt;b&gt;echo $?&lt;/b&gt; 命令查看是否 make 成功，返回 0 则通过。&lt;/p&gt;

&lt;p&gt;(3) 编译 Hadoop&lt;/p&gt;

&lt;p&gt;解压进入 hadoop 源码目录,执行编译&lt;/p&gt;

&lt;p&gt;&lt;b&gt;$ mvn package -Pdist,native -DskipTests -Dtar&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;若安装成功，系统会提示如下信息：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-jason&quot;&gt;1. [INFO] BUILD SUCCESS
2. [INFO] ------------------------------------------------
3. [INFO] Total time: 15:39.705s
4. [INFO] Finished at: Fri Nov 01 14:36:17 CST 2014
5. [INFO] Final Memory: 135M/422M
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后，在以下目录可以获取编译完成的 libhadoop:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;1. hadoop-2.2.0-src/hadoop-dist/target/hadoop-2.2.0/lib
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;将编译的 lib/native 文件夹替换原本的即可。&lt;/p&gt;

&lt;p&gt;注意：在 mvn hadoop-2.4.0 时一切正常，但编译 hadoop-2.2.0 版本时报如下错误&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-jason&quot;&gt;[ERROR] COMPILATION ERROR :
[INFO] -------------------------------------------------------------
[ERROR] /home/hduser/code/hadoop-2.2.0-src/hadoop-common-project/hadoop-
auth/src/test/java/org/apache/hadoop/security/authentication/client/AuthenticatorTestCase.java:[88
,11] error: cannot access AbstractLifeCycle
[ERROR] class file for org.mortbay.component.AbstractLifeCycle not found
/home/hduser/code/hadoop-2.2.0-src/hadoop-common-project/hadoop-
auth/src/test/java/org/apache/hadoop/security/authentication/client/AuthenticatorTestCase.java:[96
,29] error: cannot access LifeCycle
[ERROR] class file for org.mortbay.component.LifeCycle not found
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;此时，需编辑 hadoop-common-project/hadoop-auth/pom.xml 文件，添加依赖&lt;/p&gt;

&lt;div class=&quot;language-html highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nt&quot;&gt;&amp;lt;dependency&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;groupId&amp;gt;&lt;/span&gt;org.mortbay.jetty&lt;span class=&quot;nt&quot;&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;artifactId&amp;gt;&lt;/span&gt;jetty-util&lt;span class=&quot;nt&quot;&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;scope&amp;gt;&lt;/span&gt;test&lt;span class=&quot;nt&quot;&gt;&amp;lt;/scope&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/dependency&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;再次编译，这个错误解决了。&lt;/p&gt;

&lt;p&gt;3. 错误现象：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;WARN hdfs.DFSClient: DataStreamer Exception 
org.apache.hadoop.ipc.RemoteException(java.io.IOException):File /tmp/pg20417.txt._COPYING_ could only be replicated to 0 nodes instead ofminReplication (=1). 
There are 0 datanode(s) running and no node(s) are excluded in this operation.
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;发生地方:执行 &lt;b&gt;$bin/hdfs dfs –copyFromLocal /home/hadoop/test1.txt /input&lt;/b&gt; 时&lt;/p&gt;

&lt;p&gt;原因定位: 后来经过反复查看,是因为 fs.default.name 的值中的 IP 地址配置成了 localhost，导致系统找不到 hdfs，是在 datanode 的日志中发现这个错误的&lt;/p&gt;

&lt;p&gt;4. 错误现象：&lt;/p&gt;

&lt;p&gt;Namenode 正常启动,但子节点的 datanode 无法正常启动&lt;/p&gt;

&lt;p&gt;原因定位:Hadoop 文件系统格式不符，将所有子节点中的/home/hadoop/Cloud/workspace 目录删除，然后格式化 hdfs 并重启集群即可。&lt;/p&gt;

&lt;p&gt;5. 错误现象：&lt;/p&gt;

&lt;p&gt;提交任务时卡住,MapReduce 无法正常执行&lt;/p&gt;

&lt;p&gt;原因定位:这个问题纠结了两天,网上各种查,最后发现是 yarn-site.xml 文件中参数名: yarn.resoucemanager.scheduler.address 漏写了一个字母,无限捶胸顿足,希望大家引以为戒。&lt;/p&gt;

&lt;h2 id=&quot;开发环境搭建&quot;&gt;开发环境搭建&lt;/h2&gt;

&lt;p&gt;这里在 Windows 下搭建开发环境，在基于 Ubuntu 的集群上运行，架构如图所示。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2017-03-16-hadoop-implementation/hadoop-os.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;1. 安装 JDK 环境&lt;/p&gt;

&lt;p&gt;注意，这里安装的 JDK 要和集群上的版本保持一致。&lt;/p&gt;

&lt;p&gt;2. 安装 Eclipse&lt;/p&gt;

&lt;p&gt;这里楼长用 Eclipse 作为示例，下载地址：&lt;a href=&quot;http://www.eclipse.org/downloads/&quot;&gt;http://www.eclipse.org/downloads/&lt;/a&gt;。感兴趣的童鞋也可以尝试 IntelliJ，一个很不错的 IDE。&lt;/p&gt;

&lt;p&gt;3. 新建工程&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2017-03-16-hadoop-implementation/hadoop-new-project.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;4. 新建 package&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2017-03-16-hadoop-implementation/hadoop-new-package.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;5. 导入 jar 包&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2017-03-16-hadoop-implementation/hadoop-import.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;6. 编写代码&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2017-03-16-hadoop-implementation/hadoop-coding.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;7. 编译程序&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2017-03-16-hadoop-implementation/hadoop-export1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;8. 导出程序&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2017-03-16-hadoop-implementation/hadoop-export2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;9. 将 jar 包复制到 Master 节点，跳转到 Master 的 Hadoop 目录，执行：&lt;/p&gt;

&lt;p&gt;&lt;b&gt;$bin/hadoop jar ~/Cloud/WordCount.jar /input /output&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;以上。&lt;/p&gt;

&lt;hr /&gt;

</description>
        <pubDate>Thu, 16 Mar 2017 05:00:00 -0700</pubDate>
        <link>http://localhost:4000/2017/03/16/hadoop-implementation/</link>
        <guid isPermaLink="true">http://localhost:4000/2017/03/16/hadoop-implementation/</guid>
        
        <category>Big Data</category>
        
        <category>Hadoop</category>
        
        
      </item>
    
      <item>
        <title>Hey, 这是我的第一篇GitHub博客</title>
        <description>&lt;h2 id=&quot;为什么写博客&quot;&gt;为什么写博客&lt;/h2&gt;

&lt;p&gt;关于“为什么写博客”，这其实是和“博客”同样古老的话题，一百个人能给出一千个理由来。这里楼长仅仅抛砖引玉陈列一些个人教训，希望走过类似弯路的童鞋有所共鸣。同时推荐大家参考和菜头的《&lt;a href=&quot;http://www.jianshu.com/p/25de264a79cb&quot;&gt;开始写作吧&lt;/a&gt;》，刘未鹏的《&lt;a href=&quot;https://www.douban.com/note/530583920/&quot;&gt;为什么你应该（从现在开始就）写博客&lt;/a&gt;》，李笑来的《&lt;a href=&quot;http://garrolan.blogspot.com/2017/03/app33.html&quot;&gt;为什么你一定要学会写作&lt;/a&gt;》，以及 Joshua Becker 的《&lt;a href=&quot;http://www.becomingminimalist.com/15-reasons-i-think-you-should-blog/&quot;&gt;Why you should write blog&lt;/a&gt;》。&lt;/p&gt;

&lt;p&gt;&lt;b&gt;一、好记性不如烂笔头&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;时间是我们的朋友，也是我们的敌人。如果能善加利用，可以随着时间积累很多知识，但如果利用不当，不但得不到认知升级，原有的技术储备也很有可能会慢慢流失。&lt;/p&gt;

&lt;p&gt;之前在学校零零星星参与过一些项目，但遗憾的是，随着时间的推移，稍早之前做的工作很大一部分都记不清细节了。这导致了一个严重后果：再上类似项目，需要大量的返工和重新查阅资料。每每到此，我都投心疾首，悔当初一时偷懒没把当时的东西整理记录。&lt;/p&gt;

&lt;p&gt;举个例子，之前在 &lt;a href=&quot;http://metro.cs.ucla.edu/mobile_insight/&quot;&gt;MobileInsight&lt;/a&gt; 项目中第一次接触 git，主要用于团队成员间代码的同步和版本控制，所以当时对 git 命令还算比较熟悉，但之后相当长一段时间就再没用过。最近毕业在即，打算将以前的项目整理出来放到 GitHub，这才发现很多 git 命令已经记不清了，只得找出《GitHub 入门与实践》翻查命令。&lt;/p&gt;

&lt;p&gt;&lt;b&gt;二、Open Source 的魅力&lt;/b&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“通过分享，你获得了直接而快速的回报，你最终或许会发现你已将版权和“保留所有权利”抛诸脑后。新的经济学准则是：参与你作品的人越多，回报越高。在分享主义里，如果你愿意你可以保留所有权，但是我乐于分享。” by 毛向辉 《分享主义：一场思维革命》&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;相信很多人和楼长一样，第一次接触博客是从读某一篇技术帖开始的，而那篇帖子也因为帮自己解决了某个 Bug 或 Error 而挽救了当时即将崩溃的内心。也正是多次这样的经历，强化了我对技术博客的由衷好感以及诸多大牛博主的感激之情。当然，除了大量国内分享的技术博客，还有大量国外分享的代码，这些共同构成了现今的互联网精神 —— 开源！&lt;/p&gt;

&lt;p&gt;我们设想一个场景，一个办公室里有四个人，在你们共同构建的知识体系中你占40% 的比重，而其他三位各20%（好吧说人话：你比其他三位更牛一些）。如果一直保持互不交流的态势，你一直会是这个办公室里的佼佼者。However，如果另外三位仁兄互相学到对方的技能了呢？这是，你会惊喜地发现，架构体系发生了变化：60%，60%，60%，40%。也就是：27.3%，27.3%，27.3%，18.1%。&lt;/p&gt;

&lt;p&gt;再进一步，如果你跳槽去了另一个办公室，你会更加惊喜地发现，自己连18.1%也算不上了，因为你的同事们已经在他们以前各自的办公室里完成了更高质量的知识迭代。&lt;/p&gt;

&lt;p&gt;所以，一定要保持交流协作的意识，而不是抱着零和博弈的心态固步自封。无数前辈告诉我们一个道理：如果你认为自己是个大牛，一定是因为还没见识过真的大牛。&lt;/p&gt;

&lt;p&gt;&lt;b&gt;三、总有那么些事让你专注&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;生活中，总有那么些事让你兴趣昂扬且乐此不疲，比如DOTA。生活大爆炸第七季第六集中有这样一个场景，Penny过来要求点菜，Sheldon沉迷研究，说”Can’t talk, in the zone”。这种对一件事的专注也就是所谓的心流体验。对心流理论感兴趣的同学可以请教度娘或直接了解 &lt;a href=&quot;https://en.wikipedia.org/wiki/Mihaly_Csikszentmihalyi&quot;&gt;Mihaly Csikszentmihalyi&lt;/a&gt; 教授。&lt;/p&gt;

&lt;p&gt;问题来了，我们的时间都是有限的，不被这件事填充就被那件事占满，如果能把专注的对象放在对自己有提升的事情上，比如写作，难道不是两全其美吗？&lt;/p&gt;

&lt;p&gt;此外，坚持写作能成为自己持续学习的动力。为了完成一篇文章，首先需要获取第一手资料，寻找信息来源、将调研的“信息”转化为“情报”并最终为自己所用，这本身就是一个知识积累和自身提升的过程。同时，你慢慢就学会了鉴别知识：哪些是行业关注的焦点，哪些技术在三到五年内还只能是概念股。在这个过程中，你会慢慢重塑自己的思维习惯并开始学会专注。&lt;/p&gt;

&lt;p&gt;&lt;b&gt;四、思维的良好训练&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;无论语言还是文字，都是一个人大脑运转的外在表现，是思维逻辑的真实写照。语言自不必说，你身边一定有那么些人，说话滔滔不绝，却总 get 不到点；另一些人，讲话条理清晰，严谨之余不失幽默，让人听来如沐春风。单就文字而论，这种情况也是完全适用的，而要提升这方面的能力，就要经过后天系统性的训练。&lt;/p&gt;

&lt;p&gt;很多时候你以为懂了，可当自己打算写下来的时候，就会发现无从下手了。如果一件事情你不能讲清楚，十有八九你还没有完全理解。将事情写下来，慢慢就可以提高你的逻辑思维能力，分析能力，写会迫使你在你脑中搭建一个有条理的框架。&lt;/p&gt;

&lt;p&gt;就像楼长写这篇文章一样，就要将值得写博客的原因一一罗列出并逐段打磨，只有这样内容才会更加清晰，而自己也可以更好的思考。&lt;/p&gt;

&lt;p&gt;当你自己完成一篇博客（文章），再回头看别人的博客（文章）时，那种感觉是不一样的。作者为什么这么构思？如果我来写该怎么写？相信我，你距离作者文字背后的思维会更近一步。&lt;/p&gt;

&lt;p&gt;&lt;b&gt;五、探索全新的领域&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;世界不止是你的家，你的公司，你的朋友圈，你应该去发现一个更大更远的世界。通过写博客，你会知道世界上还有很多人像你一样在写博客，这些人和知识正在世界的某个角落等着你。&lt;/p&gt;

&lt;p&gt;在写这篇文章的过程中，我才知道“多说”将在6月1日关闭；也才知道阿里有个叫鬼栈的前端开发工程师，后来去了饿了么；我才要将阳志平的博客重读一遍。写的过程会让你有很多新的发现，这些新的发现都值得你去再写下来，总结分享出去。&lt;/p&gt;

&lt;p&gt;&lt;b&gt;六、赠人玫瑰，手有余香&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;隔一段时间，再回头看自己写的博客，你会发现自己正在通过这样的方式在不断的成长，这种成长在自己眼里是一种财富，在别人眼里是一张地图，你得到了收获，不断修正自己的错误，别人得到指引，避免了弯路。&lt;/p&gt;

&lt;h2 id=&quot;如何使用github搭建博客&quot;&gt;如何使用GitHub搭建博客&lt;/h2&gt;
&lt;p&gt;闲话少说，这里我将适用 GitHub 搭建博客的方法记录如下。&lt;/p&gt;

&lt;p&gt;&lt;b&gt;一、学习使用GitHub&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;首先进入GitHub并申请账号，Google输入github，点击第一条进入，如下图。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2017-03-11-the-first-blog/google-github.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;想了解GitHub的童鞋可参见知乎：&lt;a href=&quot;https://www.zhihu.com/question/19968479/&quot;&gt;https://www.zhihu.com/question/19968479/&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;进入GitHub主页后请首先注册账号。并创建一个 Repositories，命名为”&lt;em&gt;username&lt;/em&gt;.github.io”。注意，这里，&lt;em&gt;username&lt;/em&gt; 是你刚才注册的 GitHub 账号名，我的账号名是 &lt;b&gt;&lt;em&gt;liclong&lt;/em&gt;&lt;/b&gt;，因此这里填: “&lt;b&gt;&lt;em&gt;liclong&lt;/em&gt;&lt;/b&gt;.github.io”。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2017-03-11-the-first-blog/github-repositories.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;二、建立本地与GitHub的连接&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;1. 本地电脑安装 git&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;接下来我们在本地环境中实际安装 git，并进行各种设置。如果使用 Mac 可以忽略安装过程，因为系统已默认集成了这一功能，使用 Ubuntu 和 Windows 的童鞋可以参考：&lt;a href=&quot;https://git-scm.com/book/en/v2/Getting-Started-Installing-Git&quot;&gt;《Getting Started - Installing Git》&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;下面我们对本地计算机里安装的 git 进行设置，首先设置的是使用 Git 时的姓名和邮箱地址。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ git config --global user.name &quot;firstname lastname&quot;
$ git config --global user.email &quot;youemail@gmail.com&quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;设置完毕后可通过 ~/.gitconfig 文件进行更改。这里设置的姓名和邮箱地址会用在 Git 的提交日志。由于在 GitHub 上公开仓库后，这里的姓名和邮箱地址也会被一并公开，所以注意不要使用不便公开的隐私信息。&lt;/p&gt;

&lt;p&gt;此外，在 GitHub 上公开博客或源码后，前来参考的程序员可能来自世界任何地方，所以不要使用汉字，很多外国友人的中文水平远不如我们的英文水平。当然，如果不想使用真名，完全可以使用网络上的昵称。&lt;/p&gt;

&lt;p&gt;&lt;b&gt;2. 本地创建密钥&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;GitHub上连接已有仓库时的认证，是通过使用 SSH 的公开密钥认证方式进行的。现在我们来创建公开密钥认证所需的 SSH Key，并将其添加至GitHub。如果已经创建过，可以使用现有的密钥进行设置。&lt;/p&gt;

&lt;p&gt;运行下面的命令创建 SSH Key。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ ssh-keygen -t rsa -C &quot;youremail@gmail.com&quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这里，“&lt;em&gt;youremail&lt;/em&gt;@gmail.com” 部分改成你在创建GitHub账号时用的邮箱地址。最终，系统会在 Home 目录的一个隐藏文件夹 .ssh 下生成公钥 id_rsa.pub 和私钥 id_rsa。&lt;/p&gt;

&lt;p&gt;&lt;b&gt;3. 添加公钥到 GitHub&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;在GitHub上添加公钥，今后就可以用私钥进行认证了。&lt;/p&gt;

&lt;p&gt;点击右上角的账户设定按钮（Account Settings），选择 SSH and GPG Keys 菜单，就会出现如下界面。点击 Add SSH Key，会出现 Title 和 Key 两个输入框。在 Title 中输入适当的密钥名称，Key 部分粘贴 id_rsa.pub 文件里的内容。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2017-03-11-the-first-blog/github-sshkey.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;如此一来，本地电脑和远端的 GitHub 服务器就建立了可信的连接。以后可以通过 git 命令快捷的从 GitHub 克隆项目，并将修改后的项目更新到 GitHub。&lt;/p&gt;

&lt;p&gt;&lt;b&gt;三、先走一遍流程&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;要了解一个项目，最快捷的方法就是先从头到尾过一遍。所以，我们首先创建一个最简单的网页，介绍从创建 GitHub 到访问网页到整个流程，以帮助大家理解。打开终端输入如下命令：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ git clone https://github.com/liclong/liclong.github.io
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这样可以将刚才在 GitHub 上创建的 Repositories 克隆到本地，你会发现在当前路径下多了一个文件夹：“liclong.github.io”。然后后续操作可以在本地进行，只需将最终版本再上传回 GitHub 即可。我们在克隆到本地的 liclong.github.io 目录下新建一个文件：index.html，这是网站的入口。文件编辑如下：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cp&quot;&gt;&amp;lt;!DOCTYPE html&amp;gt;&lt;/span&gt;

&lt;span class=&quot;nt&quot;&gt;&amp;lt;html&amp;gt;&lt;/span&gt;

&lt;span class=&quot;nt&quot;&gt;&amp;lt;head&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;title&amp;gt;&lt;/span&gt;liclong.github.io&lt;span class=&quot;nt&quot;&gt;&amp;lt;/title&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/head&amp;gt;&lt;/span&gt;

&lt;span class=&quot;nt&quot;&gt;&amp;lt;body&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;p&amp;gt;&amp;lt;a&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;href=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;http://www.google.com&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;Link to another page&lt;span class=&quot;nt&quot;&gt;&amp;lt;/a&amp;gt;&lt;/span&gt;.&lt;span class=&quot;nt&quot;&gt;&amp;lt;/p&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/body&amp;gt;&lt;/span&gt;

&lt;span class=&quot;nt&quot;&gt;&amp;lt;/html&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;随后，将修改的文件同步回 GitHub。现在我们看一下如何将修改的东西同步回去。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ git status                //查看仓库中文件修改状况
$ git add index.html        //将文件加入暂存区
$ git commit -m &quot;the content of update&quot;
$ git push                  //现在，GitHub 上的仓库被更新了
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;打开你的浏览器，输入你刚建的 Repository 的文件名，例如我的是 liclong.github.io。如下图所示，You get it!&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2017-03-11-the-first-blog/github-link.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;说白了，GitHub 提供了这样一种页面解析功能，你既可以拿它制作博客，也可以拿它做个人主页，功能就在那里，用途任你选择。详情可参考 &lt;a href=&quot;https://pages.github.com/&quot;&gt;GitHub Pages&lt;/a&gt; 官方主页。&lt;/p&gt;

&lt;p&gt;&lt;b&gt;四、使用Jekyll进行本地调试&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;有一个问题，每次微调后都要同步回 GitHub 查看页面修改结果？ NO！&lt;/p&gt;

&lt;p&gt;理想的方式应该是，本地进行调试和预览，只把最终的版本上传至 GitHub 供大家浏览。幸运的是，Jekyll 提供这样的功能。&lt;/p&gt;

&lt;p&gt;打开 terminal, 安装 Ruby （Mac上已经预装了Ruby）。可以输入 $ ruby –version 去验证是否安装。&lt;/p&gt;

&lt;p&gt;接下来，输入sudo gem install github-pages，安装 Jekyll (gem update github-pages命令可以用来更新 Jekyll，以免 Github 服务器更新导致网站本地和线上表现不同)&lt;/p&gt;

&lt;p&gt;之后你需要在 master 下新建一个 file，命名为 Gemfile，输入&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;source 'https://rubygems.org'
gem 'github-pages'
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;运行 terminal，使用命令行移至 repository 根目录下（也就是刚才从 GitHub 上克隆下来的 liclong.github.io 目录）。之后运行&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ bundle exec jekyll serve
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;注意，如果没有前面创建的 Gemfile 文件，这个命令是执行不通过的。&lt;/p&gt;

&lt;p&gt;下面，就可以使用 Jekyll 啦，本地测试在浏览器输入 http://localhost:4000 即可。&lt;/p&gt;

&lt;p&gt;&lt;b&gt;五、学会使用Jekyll个性化博客&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;从零写一个漂亮的博客时间成本太高。更何况，每写一篇博客还要重复大量以往的工作，既耗时又耗力。为美化博客且最大限度的实现代码复用，我们充分发挥拿来主义精神，它山之石可以攻玉。&lt;/p&gt;

&lt;p&gt;浏览器中登录 GitHub 网站，进入自己的 liclong.github.io 仓库（再次强调，&lt;em&gt;liclong&lt;/em&gt;是我的用户名，大家在实际操作是将它改成自己的用户名）。&lt;/p&gt;

&lt;p&gt;随后，进入 liclong.github.io 仓库，并点击菜单栏中的 Settings。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2017-03-11-the-first-blog/github-theme.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在 theme 中，选择你喜欢的主题。这里我们以 slate 主题为例，如下图所示。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2017-03-11-the-first-blog/github-slate.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;可以查看它在 GitHub 中的代码，并 git clone 到本地。现在将里面的代码全部复制到本地的 liclong.git.io 目录，文件名重复的直接 replace。然后，进入 liclong.github.io 目录，并执行：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ git status        //查看哪些文件做过修改
$ git add .         //多个文件修改时，可以直接用.的方式实现全选
$ git commit -m &quot;this is an update&quot;
$ git push          //推送到 GitHub
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;打开浏览器，登录 &lt;a href=&quot;http://liclong.github.io&quot;&gt;http://liclong.github.io&lt;/a&gt;，你会看到 slate 主题的网页里。修改 index.html 文件即可进行修改。具体细节可实际摸索。&lt;/p&gt;

&lt;p&gt;注意，目前的 GitHub 进行了改版，以前各教程中提到的 theme 中的 “automatic page generator” 已经不在，大家不必纠结。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/2017-03-11-the-first-blog/github-answer.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;结语&quot;&gt;结语&lt;/h2&gt;

&lt;p&gt;以上。
楼长，04月于苏州。&lt;/p&gt;

&lt;hr /&gt;

</description>
        <pubDate>Fri, 10 Mar 2017 04:00:00 -0800</pubDate>
        <link>http://localhost:4000/2017/03/10/the-first-blog/</link>
        <guid isPermaLink="true">http://localhost:4000/2017/03/10/the-first-blog/</guid>
        
        <category>Web开发</category>
        
        <category>写作</category>
        
        
      </item>
    
  </channel>
</rss>
